{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare the length of two vectors\n",
    "\n",
    "This function is called `verify_length`. It takes two vectors and compares their length to make sure that they have the same length. This function is used in the second function as a preliminary check. If a prediction vector does not have the same length as a vector of actual values then there is a deeper problem that must be dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_length <- function (v1, v2 ){\n",
    "    if (length(v1) != length(v2)) {\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define accuracy metric\n",
    "\n",
    "Write a function called  `accuracy`. This function should takes two vectors as argument: \n",
    "\n",
    "1. a vector of actual values\n",
    "1. a vector of predicted values \n",
    "\n",
    "The function should do two things:\n",
    "\n",
    "1. it should use `verify_length` to make sure that the vectors have the same length.\n",
    "1. it computes the accuracy of a prediction vector where accuracy is defined by\n",
    "\n",
    "$$\\text{accuracy} =  \\sum \\left(\\text{class}_{actual} = \\text{class}_{predicted}\\right)$$\n",
    "\n",
    "= 1/n(classactual=classpredicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "177cc4ad52411f5d357f5b95e1c6c87d",
     "grade": false,
     "grade_id": "cell-a87b34e2d52345f0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "accuracy <- function (actual, predicted) \n",
    "{\n",
    "    verify_length(actual, predicted)\n",
    "    \n",
    "    # Compute the accuracy of a prediction vector using `sum`.\n",
    "        # `sum` is part of the S4 ‘Summary’ group generic. \n",
    "        # Methods for it must use the signature ‘x, ..., na.rm’.\n",
    "        # `sum` returns the sum of all the values present in its arguments.\n",
    "        # Arguments: numeric or complex or logical vectors.\n",
    "        # Logical vectors are coerced to integer vectors in contexts where \n",
    "        #    a numerical value is required, with TRUE being mapped to 1L, \n",
    "        #    FALSE to 0L and NA to NA_integer_.\n",
    "        # The sum: If all of ‘...’ are of type integer or logical, then the \n",
    "        #    sum is integer.  Otherwise it is a length-one numeric or complex vector.\n",
    "    \n",
    "    # accuracy(vector_of_actual_values, vector_of_predicted_values)\n",
    "    # accuracy(c(1,1,0,0,1),            c(1,1,1,0,0))\n",
    "    # accuracy(v_1,                     v_2)\n",
    "    \n",
    "    # Calculation: sum(actual == predicted) / length(actual)\n",
    "    # sum(actual == predicted)\n",
    "    #     sum(c(v_1[1]==v_2[1], v_1[2]==v_2[2], v_1[3]==v_2[3], v_1[4]==v_2[4], v_1[5]==v_2[5]))\n",
    "    #     sum(c(     1==1,           1==1,           0==1,           0==0,           1==0     ))\n",
    "    #     sum(c(      T,              T,              F,              T,              F       ))\n",
    "    #     sum(c(      1,              1,              0,              1,              0       )) = 3\n",
    "    # length(actual)\n",
    "    #      length(c(1,1,0,0,1)) = 5\n",
    "    # 3 / 5 = 0.60\n",
    "    \n",
    "    n = length(actual) # or length(predicted) since they both have to be the same length\n",
    "    \n",
    "    return (sum(actual == predicted) / n)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.6"
      ],
      "text/latex": [
       "0.6"
      ],
      "text/markdown": [
       "0.6"
      ],
      "text/plain": [
       "[1] 0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(c(1==1,1==1,0==1,0==0,1==0))\n",
    "length(c(1,1,0,0,1))\n",
    "sum(c(1==1,1==1,0==1,0==0,1==0)) / length(c(1,1,0,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7f2cdd12f018ee21261d810f940e069",
     "grade": true,
     "grade_id": "cell-1413eaf5951ffcb5",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(round(accuracy(c(1,1,0,0,1),c(1,1,1,0,0)), 2) == 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: You will need the code for your `accuracy` function in a later notebook.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
